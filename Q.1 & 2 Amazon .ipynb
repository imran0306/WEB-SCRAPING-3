{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a8ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Write a python program which searches all the product under a particular product from www.amazon.in.\n",
    "#The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search\n",
    "#for guitars.\n",
    "#2. In the above question, now scrape the following details of each product listed in first 3 pages of your\n",
    "#search results and save it in a data frame and csv. In case if any product has less than 3 pages in search\n",
    "#results then scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "#Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "#“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a57058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2742bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\91620\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45873f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc2bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product that we want to search : Guitar\n"
     ]
    }
   ],
   "source": [
    "# entering the product that we want to search\n",
    "user_input = input('Enter the product that we want to search : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8722f873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"c3f16702171d4960b732cb965274631d\", element=\"7ec877f4-d9e1-4d63-b37e-4c17cc9d6820\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3edcb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sending the user input to search bar\n",
    "search.send_keys(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7be783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating the search button using xpath\n",
    "search_btn = driver.find_element(By.XPATH,\"//div[@class='nav-search-submit nav-sprite']/span/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a04c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d5153",
   "metadata": {},
   "source": [
    "Q2 : In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product vertical has less than 3 pages in search results then scrape all the products available under that product vertical. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9eb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching URLs to open the pages\n",
    "urls = []          # empty list\n",
    "for i in range(0,60):      # for loop to scrape 3 pages\n",
    "    page_url = driver.find_elements(By.XPATH,\"//a[@class='a-link-normal a-text-normal']\")\n",
    "    for i in page_url:\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "        next_btn = driver.find_elements(By.XPATH,\"//li[@class='a-last']/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bc9af39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd921e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making empty list and fetching required data\n",
    "brand_name = []\n",
    "product_name = []\n",
    "ratings = []\n",
    "num_ratings = []\n",
    "prices = []\n",
    "exchange = []\n",
    "exp_delivery = []\n",
    "availability = []\n",
    "other_details = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    #fetching brand name \n",
    "    try:\n",
    "        brand = driver.find_element(By.XPATH,\"//a[@id='bylineInfo']\")\n",
    "        brand_name.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append('-')\n",
    "    \n",
    "    \n",
    "    # fetching Name of the Product\n",
    "    try:\n",
    "        product = driver.find_element(By.XPATH,\"//span[@id='productTitle']\")\n",
    "        product_name.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        product_name.append('-')\n",
    "        \n",
    "        \n",
    "\n",
    "     #fetching ratings\n",
    "    try:\n",
    "        rating = driver.find_element(By.XPATH,\"//span[@class='a-size-base a-nowrap']/span\")\n",
    "        ratings.append(rating.text)\n",
    "    except NoSuchElementException:\n",
    "        ratings.append('-')\n",
    "        \n",
    " \n",
    "    #fetching  no of ratings\n",
    "    try:\n",
    "        num_rating = driver.find_element(By.XPATH,\"//span[@id='acrCustomerReviewText']\")\n",
    "        num_ratings.append(num_rating.text)\n",
    "    except NoSuchElementException:\n",
    "        num_ratings.append('-')\n",
    "        \n",
    "\n",
    "    #fetching price of the product\n",
    "    try:\n",
    "        price = driver.find_element(By.XPATH,\"//td[@class='a-span12']\")\n",
    "        prices.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        prices.append('-')\n",
    "        \n",
    "        \n",
    "    #fetching return/exchange\n",
    "    try:\n",
    "        exch = driver.find_element(By.XPATH,\"//span[@class='a-declarative']/div/a\")\n",
    "        exchange.append(exch.text)\n",
    "    except NoSuchElementException:\n",
    "        exchange.append('-')\n",
    "        \n",
    "\n",
    "    #fetching expected delivery\n",
    "    try:\n",
    "        delivery = driver.find_element(By.XPATH,\"//div[@class='a-section a-spacing-mini']/b\")\n",
    "        exp_delivery.append(delivery.text)\n",
    "    except NoSuchElementException:\n",
    "        exp_delivery.append('-')\n",
    "        \n",
    "\n",
    "    #fetching availability information\n",
    "    try:\n",
    "        avail = driver.find_element(By.XPATH,\"//span[@class='a-size-medium a-color-success']\")\n",
    "        availability.append(avail.text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append('-')\n",
    "        \n",
    "    #other details\n",
    "    try:\n",
    "        oth_det = driver.find_element(By.XPATH,\"//ul[@class='a-unordered-list a-vertical a-spacing-mini']\")\n",
    "        other_details.append(oth_det.text)\n",
    "    except NoSuchElementException:\n",
    "        other_details.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49abc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_name),\n",
    "len(product_name),\n",
    "len(ratings),\n",
    "len(num_ratings),\n",
    "len(prices),\n",
    "len(exchange),\n",
    "len(exp_delivery),\n",
    "len(availability),\n",
    "len(other_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b02ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Name of the Product</th>\n",
       "      <th>Rating</th>\n",
       "      <th>No. of Ratings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return/Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Other Details</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand Name, Name of the Product, Rating, No. of Ratings, Price, Return/Exchange, Expected Delivery, Availability, Other Details, Product URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame for the scraped data\n",
    "\n",
    "guitar = pd.DataFrame({})\n",
    "guitar['Brand Name'] = brand_name\n",
    "guitar['Name of the Product'] = product_name\n",
    "guitar['Rating'] = ratings\n",
    "guitar['No. of Ratings'] = num_ratings\n",
    "guitar['Price'] = prices\n",
    "guitar['Return/Exchange'] = exchange\n",
    "guitar['Expected Delivery'] = exp_delivery\n",
    "guitar['Availability'] = availability\n",
    "guitar['Other Details'] = other_details\n",
    "guitar['Product URL'] = urls\n",
    "guitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e422c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
